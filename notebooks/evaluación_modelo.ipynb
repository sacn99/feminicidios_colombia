{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense, Reshape, Embedding, Concatenate, Conv2DTranspose, Conv2D, Flatten, Dropout, ReLU, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cgan_generator(latent_dim, n_cats, in_shape=(7, 7)):\n",
    "    # Label Inputs\n",
    "    in_label = Input(shape=(1,), name='Generator-Label-Input-Layer')\n",
    "    lbls = Embedding(n_cats, 50, name='Generator-Label-Embedding-Layer')(in_label)\n",
    "\n",
    "    n_nodes = in_shape[0] * in_shape[1]\n",
    "    lbls = Dense(n_nodes, name='Generator-Label-Dense-Layer')(lbls)\n",
    "    lbls = Reshape((in_shape[0], in_shape[1], 1), name='Generator-Label-Reshape-Layer')(lbls)\n",
    "\n",
    "    # Generator Inputs (latent vector)\n",
    "    in_latent = Input(shape=latent_dim, name='Generator-Latent-Input-Layer')\n",
    "\n",
    "    n_nodes = 7 * 7 * 128\n",
    "    g = Dense(n_nodes, name='Generator-Foundation-Layer')(in_latent)\n",
    "    g = ReLU(name='Generator-Foundation-Layer-Activation-1')(g)\n",
    "    g = Reshape((in_shape[0], in_shape[1], 128), name='Generator-Foundation-Layer-Reshape-1')(g)\n",
    "\n",
    "    # Combine both inputs\n",
    "    concat = Concatenate(name='Generator-Combine-Layer')([g, lbls])\n",
    "\n",
    "    # Hidden Layer 1\n",
    "    g = Conv2DTranspose(filters=128, kernel_size=(4, 4), strides=(2, 2), padding='same', name='Generator-Hidden-Layer-1')(concat)\n",
    "    g = ReLU(name='Generator-Hidden-Layer-Activation-1')(g)\n",
    "\n",
    "    # Hidden Layer 2\n",
    "    g = Conv2DTranspose(filters=128, kernel_size=(4, 4), strides=(2, 2), padding='same', name='Generator-Hidden-Layer-2')(g)\n",
    "    g = ReLU(name='Generator-Hidden-Layer-Activation-2')(g)\n",
    "\n",
    "    # Output Layer\n",
    "    output_layer = Conv2D(filters=1, kernel_size=(7, 7), activation='tanh', padding='same', name='Generator-Output-Layer')(g)\n",
    "\n",
    "    # Define model\n",
    "    model = Model([in_latent, in_label], output_layer, name='Generator')\n",
    "    return model\n",
    "\n",
    "def build_cgan_discriminator(img_shape, n_cats):\n",
    "    # Image input\n",
    "    in_img = Input(shape=img_shape, name='Discriminator-Image-Input-Layer')\n",
    "\n",
    "    # Label input\n",
    "    in_label = Input(shape=(1,), name='Discriminator-Label-Input-Layer')\n",
    "    lbls = Embedding(n_cats, 50, name='Discriminator-Label-Embedding-Layer')(in_label)\n",
    "    n_nodes = img_shape[0] * img_shape[1]\n",
    "    lbls = Dense(n_nodes, name='Discriminator-Label-Dense-Layer')(lbls)\n",
    "    lbls = Reshape(img_shape, name='Discriminator-Label-Reshape-Layer')(lbls)\n",
    "\n",
    "    # Concatenate image and label inputs\n",
    "    concat = Concatenate(name='Discriminator-Combine-Layer')([in_img, lbls])\n",
    "    # Hidden Layer 1\n",
    "    x = Conv2D(32, kernel_size=4, strides=2, padding='same', name='Discriminator-Hidden-Layer-1')(concat)\n",
    "    x = LeakyReLU(alpha=0.2, name='Discriminator-Hidden-Layer-Activation-1')(x)\n",
    "\n",
    "    # Hidden Layer 2\n",
    "    x = Conv2D(64, kernel_size=4, strides=2, padding='same', name='Discriminator-Hidden-Layer-2')(x)\n",
    "    x = LeakyReLU(alpha=0.2, name='Discriminator-Hidden-Layer-Activation-2')(x)\n",
    "\n",
    "    # Flatten and Output Layer\n",
    "    x = Flatten(name='Discriminator-Flatten-Layer')(x)\n",
    "    output_layer = Dense(1, activation='sigmoid', name='Discriminator-Output-Layer')(x)\n",
    "\n",
    "    # Define model\n",
    "    model = Model([in_img, in_label], output_layer, name='Discriminator')\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Define loss functions and optimaziers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(image_dir, img_shape, batch_size):\n",
    "    transform = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        zoom_range=0.1,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1\n",
    "    )\n",
    "\n",
    "    dataloader = transform.flow_from_directory(\n",
    "        image_dir,\n",
    "        target_size=img_shape[:2],\n",
    "        color_mode='grayscale',\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None\n",
    "    )\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "# Par√°metros\n",
    "image_dir = 'data'\n",
    "img_shape = (64, 64, 1)\n",
    "latent_dim = 100\n",
    "batch_size = 128\n",
    "num_epochs = 100\n",
    "n_cats = 10\n",
    "\n",
    "# Crear modelos y optimizadores\n",
    "generator = build_cgan_generator(latent_dim, n_cats)\n",
    "discriminator = build_cgan_discriminator(img_shape, n_cats)\n",
    "\n",
    "generator_optimizer = Adam(lr=0.0002, beta_1=0.5)\n",
    "discriminator_optimizer = Adam(lr=0.0002, beta_1=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dataloader\n",
    "dataloader = create_dataloader(image_dir, img_shape, batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##GAN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ciclo de entrenamiento\n",
    "for epoch in range(num_epochs):\n",
    "    for real_imgs in dataloader:\n",
    "        labels = tf.convert_to_tensor([int(folder.split('/')[-1]) for folder in dataloader.filepaths])  # Obtiene las etiquetas a partir de los nombres de las subcarpetas\n",
    "        labels = tf.reshape(labels, (-1, 1))\n",
    "\n",
    "        # Actualiza el discriminador\n",
    "        real_labels = tf.ones((real_imgs.shape[0], 1))\n",
    "        fake_imgs = generator([tf.random.normal((real_imgs.shape[0], latent_dim)), labels])\n",
    "        fake_labels = tf.zeros((real_imgs.shape[0], 1))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            real_preds = discriminator([real_imgs, labels])\n",
    "            fake_preds = discriminator([fake_imgs, labels])\n",
    "\n",
    "            real_loss = tf.keras.losses.binary_crossentropy(real_labels, real_preds)\n",
    "            fake_loss = tf.keras.losses.binary_crossentropy(fake_labels, fake_preds)\n",
    "            total_loss = (real_loss + fake_loss) * 0.5\n",
    "\n",
    "        disc_grads = tape.gradient(total_loss, discriminator.trainable_weights)\n",
    "        discriminator_optimizer.apply_gradients(zip(disc_grads, discriminator.trainable_weights))\n",
    "\n",
    "        # Actualiza el generador\n",
    "        sampled_labels = tf.random.uniform((real_imgs.shape[0], 1), minval=0, maxval=n_cats, dtype=tf.int32)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            fake_imgs = generator([tf.random.normal((real_imgs.shape[0], latent_dim)), sampled_labels])\n",
    "            fake_preds = discriminator([fake_imgs, sampled_labels])\n",
    "\n",
    "            gen_loss = tf.keras.losses.binary_crossentropy(tf.ones_like(fake_preds), fake_preds)\n",
    "\n",
    "        gen_grads = tape.gradient(gen_loss, generator.trainable_weights)\n",
    "        generator_optimizer.apply_gradients(zip(gen_grads, generator.trainable_weights))\n",
    "\n",
    "    # Imprime el progreso del entrenamiento\n",
    "    print(f'Epoch: {epoch + 1}, Generator Loss: {gen_loss.numpy().mean()}, Discriminator Loss: {total_loss.numpy().mean()}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
